<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CHEN Chaofeng</title>
    <link rel="icon" type="image/svg+xml" href="images/space.png">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/publications.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&family=Playfair+Display:wght@400;700&display=swap" rel="stylesheet">
    <script src="js/navigation.js"></script>
</head>
<body class="index-page">

    <div class="page-content">
        <div class="wrapper">
            <div class="profile">
                <img class="profile-pic" src="images/me.jpg" alt="Profile Photo">
                <div class="profile-info">
                    <h1>CHEN Chaofeng (陈超锋)</h1>
                    <h2 class="title-position">
                        Tenure Track Assistant Professor
                    </h2>
                    <p class="affiliation">School of Artificial Intelligence, Wuhan University</p>
                    <p>Research Areas: Computer Vision, Image Processing, Multi-modality Generative Models</p>
                    <div class="contact-info">
                        <i class="fas fa-envelope"></i> chaofenghust [at] gmail.com &nbsp;&nbsp;
                        <a href="https://github.com/chaofengc" target="_blank"><i class="fab fa-github"></i> GitHub</a>
                        <a href="https://scholar.google.com/citations?user=lxiqnI0AAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i> Google Scholar</a>
                        <a href="assets/Resume_ChenChaofeng_en.pdf" target="_blank"><i class="fas fa-file-pdf"></i> CV</a>
                        <a href="https://www.zhihu.com/people/fly-cfchen" target="_blank"><i class="fab fa-zhihu"></i> Zhihu</a>
                    </div>
                </div>
            </div>

            <section class="about">
                <h2>About Me</h2>
                <p>I am currently a tenure track Assistant Professor at School of Artificial Intelligence, Wuhan University. I was a postdoctoral research fellow at S-Lab in Nanyang Technological University, worked with <a href="https://personal.ntu.edu.sg/wslin/Home.html" target="_blank">Prof. Weisi Lin</a> and <a href="https://www.ntu.edu.sg/erian/about-us/our-people/cluster-directors/kelly-ke" target="_blank">Prof. Kelly</a>. I received my Ph.D. degree from <a href="https://www.cs.hku.hk/" target="_blank">Dept. of Computer Science at the University of Hong Kong</a>, advised by <a href="http://i.cs.hku.hk/~kykwong/" target="_blank">Dr. Kenneth K.Y. Wong</a>. Before that, I received my B.Eng. from <a href="http://www.hust.edu.cn" target="_blank">Huazhong University of Science and Technology</a>. My interests are centered around Computer Vision and Image Processing. Current research topics are: Low level vision, including image quality assessment, restoration and enhancement; Multi-modality generative models.</p>
                
                <div class="highlight" style="background-color: #fff8dc; border: 1px solid #f0c987; border-radius: 8px; padding: 15px; margin: 20px 0;">
                    <span style="color: #e74c3c; font-weight: bold; font-size: 18px;">🚩 Openings / 招生信息</span>
                    <hr style="border: none; border-top: 1px solid #f0c987; margin: 10px 0;">
                    
                    <p style="margin: 6px 0; color: #333;">
                        We are <strong>actively looking for passionate and talented students</strong> to join our research group.  
                        If you are interested in working on cutting-edge research in <strong>computer vision</strong> and <strong>deep learning</strong>,  
                        please send me an email with your <strong>resume</strong> and <strong>transcript</strong>.
                    </p>
                    
                    <p style="margin: 6px 0; color: #333;">
                        我们课题组长期欢迎<strong>有志于计算机视觉、深度学习等方向</strong>的优秀同学加入，一起探索前沿技术、完成有影响力的科研工作！
                        有意向的同学请发送邮件至我的邮箱，并附上<strong>个人简历</strong>和<strong>成绩单</strong>。
                    </p>
                    
                    <p style="margin: 6px 0; color: #333;">
                        目前，课题组正在招收<span style="color: #e74c3c; font-weight: bold; font-size: 17px;">2026年秋季</span>入学的<strong>硕士研究生</strong>和<strong>博士研究生</strong>。欢迎有兴趣的同学积极投递简历！<a href="openings.html" target="_blank">[查看招生详情]</a>
                    </p>
                </div>
            </section>
            
            <section class="news">
                <h2>Latest News</h2>
                <div class="news-container">
                    <div class="news-scroll">
                        <div class="news-item" style="color: red;">
                            <span class="date">⭐</span>
                            <span class="content">Use <code style="color: black;background-color: yellow;">pip install pyiqa</code> to try our PyTorch toolbox for Image Quality Assessment <a href="https://github.com/chaofengc/IQA-PyTorch" target="_blank">IQA-PyTorch</a>.</span>
                        </div>
                        <div class="news-item" style="color: red;">
                            <span class="date">⭐</span>
                            <span class="content">Find a comprehensive survey about Image Quality Assessment here: <a href="https://github.com/chaofengc/Awesome-Image-Quality-Assessment" target="_blank">Awesome-Image-Quality-Assessment</a>.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2025-07</span>
                            <span class="content">One paper is accepted by ICCV2025!</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2025-01</span>
                            <span class="content">Our work <a href="https://github.com/mc-lan/Text4Seg" target="_blank">Text4Seg</a> is accepted by ICLR2025!</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2024-07</span>
                            <span class="content">Four papers are accepted by ACM MM2024 with three <span style="color:red;">Oral (3.97%)</span> presentations!</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2024-07</span>
                            <span class="content">Five papers are accepted by ECCV2024 (1 first-authored, 1 Oral)!</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2024-05</span>
                            <span class="content"><a href="https://github.com/Q-Future/Q-Align" target="_blank">Q-Align</a> is accepted by ICML2024!</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2024-02</span>
                            <span class="content">Two papers (Co-authored) about IQA are accepted by CVPR2024!</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2024-01</span>
                            <span class="content"><a href="https://github.com/Q-Future/Q-Bench" target="_blank">Q-Bench</a> is accepted as <span style="color:red;">spotlight paper (4.96%)</span> by ICLR2024!</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2024-01</span>
                            <span class="content"><a href="https://github.com/chaofengc/IQA-PyTorch" target="_blank">TOPIQ</a> is accepted by Transactions on Image Processing (TIP).</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-12</span>
                            <span class="content">One paper about image super-resolution is accepted by AAAI2024.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-10</span>
                            <span class="content">We release <a href="https://q-future.github.io/Q-Instruct/" target="_blank">Q-Instruct</a>, a multi-modality dataset for low-level visual instruction tuning with large visual language models.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-09</span>
                            <span class="content">We release <a href="https://github.com/VQAssessment/Q-Bench" target="_blank">Q-Bench</a>, a systematic benchmark for multi-modality LLMs (MLLMs) on low-level vision and visual quality assessment.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-09</span>
                            <span class="content">Extension of <a href="https://github.com/VQAssessment/FAST-VQA-and-FasterVQA" target="_blank">FAST-VQA (FasterVQA)</a> get accepted by TPAMI.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-07</span>
                            <span class="content">One paper about video quality assessment is accepted by ACM MM 2023.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-07</span>
                            <span class="content">One paper about video quality assessment is accepted by ICCV 2023.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-03</span>
                            <span class="content">One paper about video quality assessment is accepted by ICME 2023.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2023-02</span>
                            <span class="content">One paper about video quality assessment is accepted by TCSVT 2023.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-12</span>
                            <span class="content">One paper about video prediction is accepted by AAAI 2023.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-11</span>
                            <span class="content">Our research team, <a href="https://github.com/QualityAssessment" target="_blank">NTU Visual Quality Assessment Group</a> is created, which aims to build efficient and explainable Visual Quality Assessment approaches.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-09</span>
                            <span class="content">One paper is accepted by NeurIPS 2022.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-07</span>
                            <span class="content">Three papers have been accepted by ECCV2022.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-06</span>
                            <span class="content">Two papers, including <a href="https://arxiv.org/abs/2202.13142" target="_blank">QuanTexSR (renamed as FeMaSR)</a> have been accepted by ACM MM2022 as <span style="color:red;">Oral presentation (5.9%)</span>.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-06</span>
                            <span class="content">One paper, <a href="https://arxiv.org/abs/2202.07358" target="_blank">FFRNet</a> about masked face recognition has been accepted by ICIP2022.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-03</span>
                            <span class="content">We release our work about blind image resolution, <a href="https://arxiv.org/abs/2202.13142" target="_blank">QuanTexSR</a>, together with the codes in <a href="https://github.com/chaofengc/QuanTexSR" target="_blank">Github</a>.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2022-02</span>
                            <span class="content">We release a PyTorch toolbox for IQA <a href="https://github.com/chaofengc/IQA-PyTorch" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/Chaofengc/IQA-PyTorch?style=social"></a> as well as a comprehensive survey <a href="https://github.com/chaofengc/Awesome-Image-Quality-Assessment" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/Chaofengc/Awesome-Image-Quality-Assessment?style=social"></a>.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2021-07</span>
                            <span class="content">One paper about HDR video reconstruction is accepted by ICCV 2021.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2021-03</span>
                            <span class="content">Our paper <a href="https://github.com/chaofengc/PSFRGAN" target="_blank">PSFR-GAN</a> about face SR has been accepted by CVPR2021.</span>
                        </div>
                        <div class="news-item">
                            <span class="date">2020-11</span>
                            <span class="content">Our paper <a href="https://github.com/chaofengc/Face-SPARNet" target="_blank">SPARNet</a> about face SR has been accepted by TIP2020.</span>
                        </div>
                    </div>
                </div>
            </section>

            <section class="experience">
                <h2>Experience</h2>
                <div class="experience-list">
                    <table>
                        <tr>
                            <td>Jul 2025 - Present</td>
                            <td>Tenure Track Assistant Professor at School of Artificial Intelligence, Wuhan University.</td>
                        </tr>
                        <tr>
                            <td>Sep 2021 - Jan 2025</td>
                            <td>Postdoctoral research fellow at S-Lab in NTU, working with <a href="https://personal.ntu.edu.sg/wslin/Home.html" target="_blank">Prof. Weisi Lin</a> and <a href="https://www.ntu.edu.sg/erian/about-us/our-people/cluster-directors/kelly-ke" target="_blank">Prof. Kelly</a></td>
                        </tr>
                        <tr>
                            <td>Mar 2021 - Aug 2021</td>
                            <td>Research Assistant at <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/index.html" target="_blank">GAP Lab CUHKSZ</a>, worked with <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/index.html" target="_blank">Dr. Xiaoguang Han</a></td>
                        </tr>
                        <tr>
                            <td>Nov 2019 - Mar 2021</td>
                            <td>Research Intern at Alibaba DAMO Academy, worked with <a href="https://www4.comp.polyu.edu.hk/~cslzhang/" target="_blank">Prof. Lei Zhang</a> and <a href="https://csxmli2016.github.io/" target="_blank">Dr. Xiaoming Li</a></td>
                        </tr>
                        <tr>
                            <td>May 2019 - Oct 2019</td>
                            <td>Research Visitor at VLLab UC Merced, worked with <a href="https://faculty.ucmerced.edu/mhyang/" target="_blank">Prof. Ming-Hsuan Yang</a></td>
                        </tr>
                        <tr>
                            <td>Jun 2018 - Mar 2019</td>
                            <td>Research Intern at Tencent AI Lab, worked with <a href="https://dblp.uni-trier.de/pers/l/Li:Zhifeng.html" target="_blank">Prof. Zhifeng Li</a> and <a href="https://www.cise.ufl.edu/~dihong/" target="_blank">Dr. Dihong Gong</a></td>
                        </tr>
                    </table>
                </div>
            </section>

            <section class="selected-publications">
                <div class="publications-header">
                    <div class="header-left">
                        <h2>Selected Publications 
                            <span class="author-notation-inline">
                                <span class="notation-item"><sup>*</sup> Co-first author, 
                                <sup>✉</sup> Corresponding author</span>
                            </span>
                        </h2>
                    </div>
                    <div class="publications-links">
                        <a href="publications.html" class="publications-link">All Publications</a>
                        <span class="link-separator">|</span>
                        <a href="https://scholar.google.com" target="_blank" class="google-scholar-link"><font color="#4285F4">G</font><font color="#DB4437">o</font><font color="#F4B400">o</font><font color="#4285F4">g</font><font color="#0F9D58">l</font><font color="#DB4437">e</font> Scholar</a>
                    </div>
                </div>
                
                <!-- Conference Publications Section -->
                <div class="publication-section">
                    <h3 class="section-title">
                        <i class="fas fa-users"></i>
                        Conference Papers
                    </h3>
                    <div class="publications-container" id="conference-publications">
                        <!-- Conference publications will be loaded from BIB file via JavaScript -->
                    </div>
                </div>
                
                <!-- Journal Publications Section -->
                <div class="publication-section">
                    <h3 class="section-title">
                        <i class="fas fa-book"></i>
                        Journal Papers
                    </h3>
                    <div class="publications-container" id="journal-publications">
                        <!-- Journal publications will be loaded from BIB file via JavaScript -->
                    </div>
                </div>
            </section>

            <section class="professional-activities">
                <h2>Professional Activities</h2>
                <ul>
                    <li><b>Conference Reviewer</b>:
                    <ul>
                        <li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
                        <li>International Conference on Computer Vision (ICCV)</li>
                        <li>European Conference on Computer Vision (ECCV)</li>
                        <li>Conference on Neural Information Processing Systems (NeurIPS)</li>
                        <li>International Conference on Learning Representations (ICLR)</li>
                        <li>Association for the Advancement of Artificial Intelligence (AAAI)</li>
                        <li>ACM International Conference on Multimedia (ACM MM)</li>
                    </ul>
                    </li>
                    <li><b>Journal Reviewer</b>:
                    <ul>
                        <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                        <li>International Journal of Computer Vision (IJCV)</li>
                        <li>IEEE Transactions on Image Processing (TIP)</li>
                        <li>IEEE Transactions on Multimedia (TMM)</li>
                        <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
                        <li>Elsevier Journal of Neurocomputing (Neurocomputing)</li>
                    </ul>
                </ul>
            </section>

            <section class="awards">
                <h2>Awards</h2>
                <ul class="awards-list">
                    <li>
                        <strong>Hong Kong PhD Fellowship</strong> - The University of Hong Kong (2015)
                    </li>
                    <li>
                        <strong>National Scholarship</strong> - Huazhong University of Science and Technology (2011)
                    </li>
                </ul>
            </section>

            <section class="teaching">
                <h2>Teaching</h2>
                <table class="teaching-table">
                    <thead>
                        <tr>
                            <th>Institution</th>
                            <th>Semester</th>
                            <th>Course</th>
                            <th>Role</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>SYSU</td>
                            <td>2025 Spring</td>
                            <td>AI236 Principles of Artificial Intelligence <br> AI238 Experiment of Artificial Intelligence</td>
                            <td>Lecture <br>TA: Xia Chen, Guiyong Zheng</td>
                        </tr>
                        <tr>
                            <td>HKU</td>
                            <td>2017 Spring</td>
                            <td>COMP3317 Computer Vision</td>
                            <td>Teaching Assistant</td>
                        </tr>
                        <tr>
                            <td>HKU</td>
                            <td>2016 Fall</td>
                            <td>COMP2396 Object-Oriented Programming and Java</td>
                            <td>Teaching Assistant</td>
                        </tr>
                        <tr>
                            <td>HKU</td>
                            <td>2016 Spring</td>
                            <td>COMP2396 Object-Oriented Programming and Java</td>
                            <td>Teaching Assistant</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section>
                <div id="clustrmap-container">
                    <p id="clustrmap-loading">Loading visitor map...</p>
                </div>
            </section>

        </div>
    </div>
    
    <footer class="site-footer" id="site-footer">
        <!-- Footer content will be generated by footer.js -->
    </footer>

    <script src="js/bibtex-parser.js"></script>
    <script src="js/publications.js"></script>
    
    <!-- Async Clustrmap Loading -->
    <script>
        // Load clustrmap asynchronously after page content is ready
        function loadClustrmap() {
            const loadingText = document.getElementById('clustrmap-loading');
            const container = document.getElementById('clustrmap-container');
            
            if (loadingText && container) {
                // Create and load the clustrmap script
                const script = document.createElement('script');
                script.type = 'text/javascript';
                script.id = 'clustrmaps';
                script.async = true;
                script.src = '//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=_WPYBsWS3jdK-Qk2uEpzsJESFoZAn23tijknLzpnvis';
                
                // Handle script load completion
                script.onload = function() {
                    // Remove loading text when map loads
                    setTimeout(() => {
                        if (loadingText) {
                            loadingText.remove();
                        }
                    }, 500);
                };
                
                script.onerror = function() {
                    loadingText.textContent = 'Unable to load visitor map';
                };
                
                // Append script to container
                container.appendChild(script);
            }
        }
        
        // Load clustrmap after a short delay to prioritize main content
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', () => {
                setTimeout(loadClustrmap, 1000);
            });
        } else {
            setTimeout(loadClustrmap, 1000);
        }
    </script>
    <script src="js/animations.js"></script>
    <script src="js/footer.js"></script>
</body>
</html>